{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1f1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.search_tools import WebSearchTool, WikipediaTool, ArxivSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c69401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VarunFoujdhar\\OneDrive - ADA Global\\Documents\\Agentic_army\\tools\\search_tools.py:13: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most significant breakthroughs in quantum computing  https://interestingengineering.com/science/5-breakthroughs-in-quantum-computing\n",
      "Quantum Computing News: ICQE 2025 & Latest Quantum … Jun 17, 2025 · Stay updated on quantum computing news: highlights from ICQE 2025 on energy and sustainability, plus the latest breakthroughs in quantum research and tech. https://www.spinquanta.com/news-detail/latest-quantum-computing-news-and-quantum-research\n",
      "Latest Advancements in Quantum Computing Technology Oct 12, 2024 · In 2023, scientists at the University of Chicago achieved a milestone by extending qubit coherence times to over five seconds, a significant improvement that brings us closer to … https://quantaintelligence.ai/2024/10/12/technology/latest-advancements-in-quantum-computing-technology\n",
      "Microsoft unveils Majorana 1, the world’s first quantum processor ... Feb 19, 2025 · Built with a breakthrough class of materials called a topoconductor, Majorana 1 marks a transformative leap toward practical quantum computing. Quantum computers … https://azure.microsoft.com/en-us/blog/quantum/2025/02/19/microsoft-unveils-majorana-1-the-worlds-first-quantum-processor-powered-by-topological-qubits/\n",
      "Quantum Computing in 2025: Breakthroughs & Challenges Mar 19, 2025 · Quantum computing is no longer just a theoretical concept—2025 has seen major breakthroughs in quantum hardware, algorithms, and real-world applications. Tech giants like … https://techspark.in/future-tech/quantum-computing-2025-breakthroughs-challenges\n",
      "Wikipedia lookup failed: Page id \"quantum computering\" does not match any pages. Try another id! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VarunFoujdhar\\OneDrive - ADA Global\\Documents\\Agentic_army\\tools\\search_tools.py:56: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for res in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rise of Quantum Internet Computing http://arxiv.org/abs/2208.00733v1\n",
      "Unconventional Quantum Computing Devices http://arxiv.org/abs/quant-ph/0003151v1\n",
      "Geometrical perspective on quantum states and quantum computation http://arxiv.org/abs/1311.4939v1\n"
     ]
    }
   ],
   "source": [
    "# Web search\n",
    "web_results = WebSearchTool.search(\"quantum computing latest breakthroughs\", num_results=5)\n",
    "for r in web_results:\n",
    "    print(r[\"title\"], r[\"snippet\"], r[\"url\"])\n",
    "\n",
    "# Wikipedia summary\n",
    "wiki_results = WikipediaTool.search(\"Quantum computing\")\n",
    "print(wiki_results[0][\"snippet\"], wiki_results[0][\"url\"])\n",
    "\n",
    "# arXiv papers\n",
    "arxiv_results = ArxivSearchTool.search(\"quantum computing\", max_results=3)\n",
    "for paper in arxiv_results:\n",
    "    print(paper[\"title\"], paper[\"url\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ab57c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(7, 33), match='arxiv.org/abs/2208.00733v1'>\n",
      "<re.Match object; span=(7, 39), match='arxiv.org/abs/quant-ph/0003151v1'>\n",
      "The Rise of Quantum Internet Computing\n",
      "arXiv ID: 2208.00733v1\n",
      "URL: http://arxiv.org/abs/2208.00733v1\n",
      "PDF downloaded to: data/arxiv/files\\2208.00733v1(The Rise of Quantum Internet Computing).pdf\n",
      "Unconventional Quantum Computing Devices\n",
      "arXiv ID: quant-ph/0003151v1\n",
      "URL: http://arxiv.org/abs/quant-ph/0003151v1\n",
      "PDF downloaded to: data/arxiv/files\\quant-ph_0003151v1(Unconventional Quantum Computing Devices).pdf\n"
     ]
    }
   ],
   "source": [
    "# Search for papers\n",
    "results = ArxivSearchTool.search(\"quantum computing\", max_results=2)\n",
    "for paper in results:\n",
    "    print(paper[\"title\"])\n",
    "    print(\"arXiv ID:\", paper[\"arxiv_id\"])\n",
    "    print(\"URL:\", paper[\"url\"])\n",
    "    \n",
    "    # Download the first paper found\n",
    "    saved_path = ArxivSearchTool.download_pdf(paper[\"arxiv_id\"],paper_title=paper['title'])\n",
    "    print(\"PDF downloaded to:\", saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0738efd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_download\\\\test.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m search = arxiv.Search(id_list=[\u001b[33m\"\u001b[39m\u001b[33m2506.01463v1\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      5\u001b[39m paper = \u001b[38;5;28mnext\u001b[39m(client.results(search))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mpaper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest_download\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VarunFoujdhar\\anaconda3\\envs\\agentic_army\\Lib\\site-packages\\arxiv\\__init__.py:219\u001b[39m, in \u001b[36mResult.download_pdf\u001b[39m\u001b[34m(self, dirpath, filename, download_domain)\u001b[39m\n\u001b[32m    217\u001b[39m path = os.path.join(dirpath, filename)\n\u001b[32m    218\u001b[39m pdf_url = Result._substitute_domain(\u001b[38;5;28mself\u001b[39m.pdf_url, download_domain)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m written_path, _ = \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m written_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VarunFoujdhar\\anaconda3\\envs\\agentic_army\\Lib\\urllib\\request.py:251\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# Handle temporary file setup.\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     tfp = \u001b[38;5;28mopen\u001b[39m(filename, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    253\u001b[39m     tfp = tempfile.NamedTemporaryFile(delete=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'test_download\\\\test.pdf'"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "client = arxiv.Client()\n",
    "search = arxiv.Search(id_list=[\"2506.01463v1\"])\n",
    "paper = next(client.results(search))\n",
    "paper.download_pdf(dirpath=\"test_download\", filename=\"test.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea67071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "\n",
    "client = arxiv.Client()\n",
    "search = arxiv.Search(id_list=[\"2506.01463v1\"])\n",
    "paper = next(client.results(search))\n",
    "paper.download_pdf(dirpath=\"test_download\", filename=\"test.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16158b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/arxiv/files\\\\2506.01463v1(test).pdf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ArxivSearchTool.download_pdf(arxiv_id='2506.01463v1',paper_title='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29677fb1",
   "metadata": {},
   "source": [
    "### Document loading test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1762916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.document_loaders import PdfDocumentLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d35278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 4\n",
      "First chunk preview: Data Scientist with 3 years of hands-on experience in machine learning, deep learning, and AI-driven\n",
      "software engineering. Demonstrated expertise in building and deploying end-to-end ML pipelines,\n",
      "int\n"
     ]
    }
   ],
   "source": [
    "# 1. Load PDF(s)\n",
    "docs = PdfDocumentLoader.load_documents(\"varun_kumar_foujdhar.pdf\")\n",
    "\n",
    "# 2. Chunk loaded Docs for RAG\n",
    "chunks = PdfDocumentLoader.chunk_documents(docs, chunk_size=1000, overlap=200)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(\"First chunk preview:\", chunks[0][:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d3b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '''First chunk preview: Data Scientist with 3 years of hands-on experience in machine learning, deep learning, and AI-driven\n",
    "software engineering. Demonstrated expertise in building and deploying end-to-end ML pipelines,'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "140dc080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ew: Data Scientist with 3 years of hands-on experience in machine learning, deep learning, and AI-driven\\nsoftware engineering. Demonstrated expertise in building and deploying end-to-end ML pipelines,'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff7d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.document_loaders import PdfDocumentLoader\n",
    "from tools.vectorstore_manager import ChromaVectorStoreManager\n",
    "\n",
    "# 1. Load and chunk PDF\n",
    "docs = PdfDocumentLoader.load_documents(\"varun_kumar_foujdhar.pdf\")\n",
    "chunks = PdfDocumentLoader.chunk_documents(docs)\n",
    "\n",
    "# 2. Build vector store\n",
    "vs_manager = ChromaVectorStoreManager()\n",
    "vector_db = vs_manager.build_vector_store(chunks)\n",
    "\n",
    "# 3. Retrieve for a query\n",
    "retrieved_docs = vs_manager.retrieve_chunks(\"ADA Digital Analytics Private Limited,\", vector_db, top_k=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a9cf022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: oduction systems, and developing scalable analytics products and intelligent\n",
      "automation. Led the design of advanced data infrastructure, real-time ML-powered platforms, and\n",
      "conversational AI systems. Proven ability to optimize workflows, drive actionable business insights, and\n",
      "deliver secure, high-impact AI solutions that solve complex problems and enhance operational efficiency.\n",
      "ADA Digital Analytics Private Limited,\n",
      "Data Scientist\n",
      "Cognizant Technology Solutions Corporation\n",
      "Data Analyst\n",
      "Designed and implemented production ML solutions across multiple products, building robust pipelines\n",
      "and APIs that power commerce analytics dashboards, conversational AI chatbots, and data assistants.\n",
      "Led backend engineering for a bespoke analytics platform: architected a star schema for orders/traffic\n",
      "data and built Airflow ETL to ingest 50k+ records daily with sub-30-minute latency.\n",
      "Developed 30+ scalable Django REST endpoints serving thousands of daily calls, optimizing with Redis\n",
      "caching and read-replicas to achieve P99 response times under 3 seconds.\n",
      "Productionized advanced ML models—deploying demand forecasting (LSTM/TCN, ~10% MAPE) and\n",
      "price elasticity regressions—integrated into a dynamic Price Impact Simulator for actionable KPI\n",
      "projections.\n",
      "Strengthened engineering quality and security by integrating modular role-based access controls  and\n",
      "collaborating with cross-functional teams for seamless system delivery and optimization.\n",
      "Performed data extraction, transformation, and analysis using Python and SQL to meet business and\n",
      "technical requirements.\n",
      "Automated data visualization and reporting workflows, enabling real-time insights for data-driven\n",
      "decision-making.\n",
      "Developed interactive dashboards in Tableau, improving data accessibility and comprehension for\n",
      "stakeholders.\n",
      "Optimized SQL queries and data pipelines, reducing processing time and enhancing report accuracy.\n",
      "September 2023 - Present\n",
      "Feb 2022 - Jan 2023\n",
      "PROFILE SUMMARY\n",
      "+91-9886944462 · varunfoujdhar004@gmail.com · LinkedIn · GitHub\n",
      "Bengaluru, karnataka\n",
      "VARUN KUMAR FOUJDHAR\n",
      "PROFESSIONAL EXPERIENCE\n",
      "TECHNICAL SKILLS\n",
      "Programming & Frameworks: Python, Django, Git\n",
      "Machine Learning & AI: ML, Deep Learning, Generative AI (LLMs, RAG)\n",
      "Databases & Storage: MySQL, PostgreSQL, Redis, ChromaDB, AWS S3\n",
      "AI Workflow & Orchestration: Airflow, LangChain, LangGraph\n",
      "Cloud: AWS (RDS, S3)\n",
      "Metadata: {}\n"
     ]
    }
   ],
   "source": [
    "for doc in retrieved_docs:\n",
    "    print(\"Content:\", doc.page_content)\n",
    "    print(\"Metadata:\", doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c7774c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_army",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
