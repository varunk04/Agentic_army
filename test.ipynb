{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1f1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.search_tools import WebSearchTool, WikipediaTool, ArxivSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c69401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VarunFoujdhar\\OneDrive - ADA Global\\Documents\\Agentic_army\\tools\\search_tools.py:13: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most significant breakthroughs in quantum computing  https://interestingengineering.com/science/5-breakthroughs-in-quantum-computing\n",
      "Quantum Computing News: ICQE 2025 & Latest Quantum … Jun 17, 2025 · Stay updated on quantum computing news: highlights from ICQE 2025 on energy and sustainability, plus the latest breakthroughs in quantum research and tech. https://www.spinquanta.com/news-detail/latest-quantum-computing-news-and-quantum-research\n",
      "Latest Advancements in Quantum Computing Technology Oct 12, 2024 · In 2023, scientists at the University of Chicago achieved a milestone by extending qubit coherence times to over five seconds, a significant improvement that brings us closer to … https://quantaintelligence.ai/2024/10/12/technology/latest-advancements-in-quantum-computing-technology\n",
      "Microsoft unveils Majorana 1, the world’s first quantum processor ... Feb 19, 2025 · Built with a breakthrough class of materials called a topoconductor, Majorana 1 marks a transformative leap toward practical quantum computing. Quantum computers … https://azure.microsoft.com/en-us/blog/quantum/2025/02/19/microsoft-unveils-majorana-1-the-worlds-first-quantum-processor-powered-by-topological-qubits/\n",
      "Quantum Computing in 2025: Breakthroughs & Challenges Mar 19, 2025 · Quantum computing is no longer just a theoretical concept—2025 has seen major breakthroughs in quantum hardware, algorithms, and real-world applications. Tech giants like … https://techspark.in/future-tech/quantum-computing-2025-breakthroughs-challenges\n",
      "Wikipedia lookup failed: Page id \"quantum computering\" does not match any pages. Try another id! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VarunFoujdhar\\OneDrive - ADA Global\\Documents\\Agentic_army\\tools\\search_tools.py:56: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for res in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rise of Quantum Internet Computing http://arxiv.org/abs/2208.00733v1\n",
      "Unconventional Quantum Computing Devices http://arxiv.org/abs/quant-ph/0003151v1\n",
      "Geometrical perspective on quantum states and quantum computation http://arxiv.org/abs/1311.4939v1\n"
     ]
    }
   ],
   "source": [
    "# Web search\n",
    "web_results = WebSearchTool.search(\"quantum computing latest breakthroughs\", num_results=5)\n",
    "for r in web_results:\n",
    "    print(r[\"title\"], r[\"snippet\"], r[\"url\"])\n",
    "\n",
    "# Wikipedia summary\n",
    "wiki_results = WikipediaTool.search(\"Quantum computing\")\n",
    "print(wiki_results[0][\"snippet\"], wiki_results[0][\"url\"])\n",
    "\n",
    "# arXiv papers\n",
    "arxiv_results = ArxivSearchTool.search(\"quantum computing\", max_results=3)\n",
    "for paper in arxiv_results:\n",
    "    print(paper[\"title\"], paper[\"url\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ab57c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(7, 33), match='arxiv.org/abs/2208.00733v1'>\n",
      "<re.Match object; span=(7, 39), match='arxiv.org/abs/quant-ph/0003151v1'>\n",
      "The Rise of Quantum Internet Computing\n",
      "arXiv ID: 2208.00733v1\n",
      "URL: http://arxiv.org/abs/2208.00733v1\n",
      "PDF downloaded to: data/arxiv/files\\2208.00733v1(The Rise of Quantum Internet Computing).pdf\n",
      "Unconventional Quantum Computing Devices\n",
      "arXiv ID: quant-ph/0003151v1\n",
      "URL: http://arxiv.org/abs/quant-ph/0003151v1\n",
      "PDF downloaded to: data/arxiv/files\\quant-ph_0003151v1(Unconventional Quantum Computing Devices).pdf\n"
     ]
    }
   ],
   "source": [
    "# Search for papers\n",
    "results = ArxivSearchTool.search(\"quantum computing\", max_results=2)\n",
    "for paper in results:\n",
    "    print(paper[\"title\"])\n",
    "    print(\"arXiv ID:\", paper[\"arxiv_id\"])\n",
    "    print(\"URL:\", paper[\"url\"])\n",
    "    \n",
    "    # Download the first paper found\n",
    "    saved_path = ArxivSearchTool.download_pdf(paper[\"arxiv_id\"],paper_title=paper['title'])\n",
    "    print(\"PDF downloaded to:\", saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0738efd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_download\\\\test.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m search = arxiv.Search(id_list=[\u001b[33m\"\u001b[39m\u001b[33m2506.01463v1\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      5\u001b[39m paper = \u001b[38;5;28mnext\u001b[39m(client.results(search))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mpaper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest_download\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VarunFoujdhar\\anaconda3\\envs\\agentic_army\\Lib\\site-packages\\arxiv\\__init__.py:219\u001b[39m, in \u001b[36mResult.download_pdf\u001b[39m\u001b[34m(self, dirpath, filename, download_domain)\u001b[39m\n\u001b[32m    217\u001b[39m path = os.path.join(dirpath, filename)\n\u001b[32m    218\u001b[39m pdf_url = Result._substitute_domain(\u001b[38;5;28mself\u001b[39m.pdf_url, download_domain)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m written_path, _ = \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m written_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VarunFoujdhar\\anaconda3\\envs\\agentic_army\\Lib\\urllib\\request.py:251\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# Handle temporary file setup.\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     tfp = \u001b[38;5;28mopen\u001b[39m(filename, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    253\u001b[39m     tfp = tempfile.NamedTemporaryFile(delete=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'test_download\\\\test.pdf'"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "client = arxiv.Client()\n",
    "search = arxiv.Search(id_list=[\"2506.01463v1\"])\n",
    "paper = next(client.results(search))\n",
    "paper.download_pdf(dirpath=\"test_download\", filename=\"test.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea67071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "\n",
    "client = arxiv.Client()\n",
    "search = arxiv.Search(id_list=[\"2506.01463v1\"])\n",
    "paper = next(client.results(search))\n",
    "paper.download_pdf(dirpath=\"test_download\", filename=\"test.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16158b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/arxiv/files\\\\2506.01463v1(test).pdf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ArxivSearchTool.download_pdf(arxiv_id='2506.01463v1',paper_title='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29677fb1",
   "metadata": {},
   "source": [
    "### Document loading test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1762916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.document_loaders import PdfDocumentLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0aec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Scientist with 3 years of hands-on experience in machine learning, deep learning, and AI-driven\n",
      "software engineering. Demonstrated expertise in building and deploying end-to-end ML pipelines,\n",
      "integrating AI solutions into production systems, and developing scalable analytics products and intelligent\n",
      "automation. Led the design of advanced data infrastructure, real-time ML-powered platforms, and\n",
      "conversational AI systems. Proven ability to optimize workflows, drive actionable business insight\n"
     ]
    }
   ],
   "source": [
    "from tools.document_loaders import PdfDocumentLoader\n",
    "docs = PdfDocumentLoader.load_documents(\"varun_kumar_foujdhar.pdf\")\n",
    "print(docs[0].page_content[:500])  # Preview some text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3fe099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Canva (Renderer mixed)', 'creator': 'Canva (Renderer mixed)', 'creationdate': '2025-07-17T18:50:41+00:00', 'title': \"varun's resume\", 'moddate': '2025-07-17T18:50:40+00:00', 'keywords': 'DAGeKtkyAGk,BAD0PuXeAFw,02', 'author': 'varun kumar', 'source': 'varun_kumar_foujdhar.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Data Scientist with 3 years of hands-on experience in machine learning, deep learning, and AI-driven\\nsoftware engineering. Demonstrated expertise in building and deploying end-to-end ML pipelines,\\nintegrating AI solutions into production systems, and developing scalable analytics products and intelligent\\nautomation. Led the design of advanced data infrastructure, real-time ML-powered platforms, and\\nconversational AI systems. Proven ability to optimize workflows, drive actionable business insights, and\\ndeliver secure, high-impact AI solutions that solve complex problems and enhance operational efficiency.\\nADA Digital Analytics Private Limited,\\nData Scientist\\nCognizant Technology Solutions Corporation\\nData Analyst\\nDesigned and implemented production ML solutions across multiple products, building robust pipelines\\nand APIs that power commerce analytics dashboards, conversational AI chatbots, and data assistants.\\nLed backend engineering for a bespoke analytics platform: architected a star schema for orders/traffic\\ndata and built Airflow ETL to ingest 50k+ records daily with sub-30-minute latency.\\nDeveloped 30+ scalable Django REST endpoints serving thousands of daily calls, optimizing with Redis\\ncaching and read-replicas to achieve P99 response times under 3 seconds.\\nProductionized advanced ML models—deploying demand forecasting (LSTM/TCN, ~10% MAPE) and\\nprice elasticity regressions—integrated into a dynamic Price Impact Simulator for actionable KPI\\nprojections.\\nStrengthened engineering quality and security by integrating modular role-based access controls  and\\ncollaborating with cross-functional teams for seamless system delivery and optimization.\\nPerformed data extraction, transformation, and analysis using Python and SQL to meet business and\\ntechnical requirements.\\nAutomated data visualization and reporting workflows, enabling real-time insights for data-driven\\ndecision-making.\\nDeveloped interactive dashboards in Tableau, improving data accessibility and comprehension for\\nstakeholders.\\nOptimized SQL queries and data pipelines, reducing processing time and enhancing report accuracy.\\nSeptember 2023 - Present\\nFeb 2022 - Jan 2023\\nPROFILE SUMMARY\\n+91-9886944462 · varunfoujdhar004@gmail.com · LinkedIn · GitHub\\nBengaluru, karnataka\\nVARUN KUMAR FOUJDHAR\\nPROFESSIONAL EXPERIENCE\\nTECHNICAL SKILLS\\nProgramming & Frameworks: Python, Django, Git\\nMachine Learning & AI: ML, Deep Learning, Generative AI (LLMs, RAG)\\nDatabases & Storage: MySQL, PostgreSQL, Redis, ChromaDB, AWS S3\\nAI Workflow & Orchestration: Airflow, LangChain, LangGraph\\nCloud: AWS (RDS, S3)'),\n",
       " Document(metadata={'producer': 'Canva (Renderer mixed)', 'creator': 'Canva (Renderer mixed)', 'creationdate': '2025-07-17T18:50:41+00:00', 'title': \"varun's resume\", 'moddate': '2025-07-17T18:50:40+00:00', 'keywords': 'DAGeKtkyAGk,BAD0PuXeAFw,02', 'author': 'varun kumar', 'source': 'varun_kumar_foujdhar.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='Commerce Intelligence Platform\\nAI-Powered eCommerce Chatbot\\nDesigned an orders-/traffic-centric star schema and orchestrated Airflow DAGs that ingest ≈ 50 k new\\nrows per day and land inside 15 minutes of source arrival, keeping dashboards near real time.\\nShipped 30 + Django REST endpoints; query tuning, Redis caching, and read-replicas hold P99 ≤ 3 s\\nwhile serving thousands of daily calls from the React front end.\\nDemand forecasting – deployed deep-learning sequence models (LSTM/TCN) per SKU × channel,\\nreaching ≈ 10 % MAPE.\\nPrice elasticity – fitted log-log regressions to derive elasticity coefficients ( ε ); the simulator combines ε\\nwith the forecast, so a 5 % ASP drop applied to the next 60 days instantly recalculates units-sold, GMV,\\nand ASP deltas.\\nSurfaced through an interactive Price Impact Simulator that lets users test model-suggested discounts\\nand see KPI projections live.\\nEngineered a modular role-based access-control system for Django: defined role/permission schema, ,\\nbuilt policy middleware that enforces rules across every API and dashboard\\nDeveloped a multi-agent AI chatbot as a virtual sales assistant, mimicking human-like conversations to\\ngather user preferences.\\nDesigned a dual-agent system: Agent 1 dynamically captures and summarizes user preferences, Agent 2\\nperforms RAG-based product retrieval using ChromaDB for precise recommendations.\\nIntegrated automated product catalog updates, ensuring real-time synchronization for relevant\\nrecommendations.\\nEngineered structured output formatting with embedded product links, enabling seamless navigation.\\nPROJECTS\\nIntelligent Data Query & Visualization Assistant\\nDeveloped an AI-powered query assistant that converts natural language into SQL and visualizations,\\nenabling business users to extract insights without writing code.\\nBuilt custom database connectors for seamless integration across diverse database architectures.\\nImplemented PII masking and a data security layer to prevent exposure of sensitive business data.\\nDesigned a Question Examiner & Spell Checker Tool for context-aware query validation and\\ncorrections.\\nIntegrated a Memory Function for multi-turn conversations, allowing users to reference previous\\nqueries.\\nADA-Aqua Award (Q3 2024): Recognized for exceptional performance and contributions to key\\nprojects at ADA.\\nAWARDS & RECOGNITION\\nEDUCATION\\nBachelors in Engineer, RNSIT 2017-2021\\nIDPU, computer science 2015-2017')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35278e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_army",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
